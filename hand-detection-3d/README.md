# Hand Detection 3D Integration for SignBridge

This directory contains the Hand Detection 3D integration for your SignBridge platform at [https://github.com/invecta/signbridge-app](https://github.com/invecta/signbridge-app).

## ğŸ¯ What This Adds to Your SignBridge

Your existing SignBridge platform will now have:
- **Real-time hand tracking** using MediaPipe
- **Unity 3D hand model control** via UDP communication
- **Enhanced sign recognition** with hand landmark data
- **Web interface** for easy access
- **Multiple deployment options** (web, Python backend, Unity)

## ğŸ“ Integration Structure

```
hand-detection-3d/
â”œâ”€â”€ web/                    # Web application files
â”‚   â””â”€â”€ index.html         # Main web interface
â”œâ”€â”€ python/                 # Python backend files
â”‚   â”œâ”€â”€ signbridge_hand_tracker.py  # Main integration
â”‚   â”œâ”€â”€ simple_hand_tracker.py      # Simplified version
â”‚   â”œâ”€â”€ signbridge_integration.py   # Full integration
â”‚   â””â”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ unity/                  # Unity integration files
â”‚   â”œâ”€â”€ SignBridgeConnector.cs      # API connector
â”‚   â”œâ”€â”€ SignBridgeTestManager.cs   # Testing component
â”‚   â””â”€â”€ UDPReceive.cs       # UDP communication
â””â”€â”€ docs/                   # Documentation
    â””â”€â”€ SIGNBRIDGE_INTEGRATION_GUIDE.md
```

## ğŸš€ Quick Start

### Option 1: Web Interface (Easiest)
```bash
cd web
# Open index.html in your browser
# Or serve with: python -m http.server 8000
```

### Option 2: Python Backend
```bash
cd python
pip install -r requirements.txt
python signbridge_hand_tracker.py
```

### Option 3: Unity Integration
```bash
cd unity
# Import .cs files into your Unity project
# Configure UDP receiver on port 5052
```

## ğŸ”§ Integration with Your Existing SignBridge

### Add These API Endpoints to Your Backend:
```python
@app.route('/api/hand-tracking/start', methods=['POST'])
def start_hand_tracking():
    """Start hand tracking session"""
    return jsonify({
        'success': True,
        'session_id': generate_session_id(),
        'message': 'Hand tracking started'
    })

@app.route('/api/hand-tracking/landmarks', methods=['POST'])
def process_hand_landmarks():
    """Process hand landmark data"""
    landmarks = request.json.get('landmarks', [])
    result = recognize_sign_from_landmarks(landmarks)
    return jsonify(result)
```

### Update Your Docker Configuration:
```dockerfile
# Add to your existing Dockerfile
RUN pip install mediapipe opencv-python numpy requests
COPY hand-detection-3d/ /app/hand-detection-3d/
EXPOSE 5052/udp
```

### Update Your Kubernetes Deployment:
```yaml
# Add to your existing k8s deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: signbridge-hand-tracking
spec:
  replicas: 2
  selector:
    matchLabels:
      app: signbridge-hand-tracking
  template:
    spec:
      containers:
      - name: hand-tracking
        image: signbridge/hand-tracking:latest
        ports:
        - containerPort: 5052
          protocol: UDP
```

## ğŸ“Š Enhanced Features

### Real-time Communication Flow:
1. **Camera Input** â†’ MediaPipe hand detection
2. **Hand Landmarks** â†’ SignBridge API processing
3. **Sign Recognition** â†’ Your existing ML models
4. **Avatar Animation** â†’ 3D model updates
5. **Unity Control** â†’ Real-time hand model

### Performance Benefits:
- **Enhanced accuracy** with hand landmark data
- **Real-time processing** for immediate feedback
- **3D visualization** for better user experience
- **Multi-modal input** combining vision and gestures

## ğŸ¯ Current Status

âœ… **Working Components:**
- Python backend sending data to Unity (63 coordinates)
- SignBridge API connected (71 signs available)
- Web interface functional
- UDP communication active
- Real-time hand tracking simulation

âœ… **Ready for Integration:**
- All files organized and ready
- Documentation complete
- Multiple deployment options available
- Compatible with your existing infrastructure

## ğŸ“ Next Steps

1. **Copy this folder** to your SignBridge repository
2. **Update your API** with hand tracking endpoints
3. **Deploy using your existing infrastructure**
4. **Test the integration** with real users

## ğŸ”— Links

- **Your SignBridge Repository**: https://github.com/invecta/signbridge-app
- **SignBridge Platform**: https://signbridgeproduction-70e5b1074092.herokuapp.com/
- **Integration Guide**: See `docs/SIGNBRIDGE_INTEGRATION_GUIDE.md`

---

**ğŸ‰ Your SignBridge platform will now have advanced hand tracking capabilities!**

This integration transforms your existing "Computer Vision Communication Assistant for Deaf and Hearing Individuals" into an even more powerful and accurate platform.
